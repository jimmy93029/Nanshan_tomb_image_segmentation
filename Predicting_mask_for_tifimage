{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3suBQ+oB1ZiI57TbPQIxM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmy93029/Nanshan_tomb_image_segmentation/blob/master/Predicting_mask_for_tifimage\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install package"
      ],
      "metadata": {
        "id": "OmDnP3PR1FOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install segment-geospatial"
      ],
      "metadata": {
        "id": "2mH34ZRJ0hgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### inputs and setting"
      ],
      "metadata": {
        "id": "hH-MJJGF1JjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "inputs = {\n",
        "      \"model_arch\": 'yolo_nas_l',\n",
        "      \"num_classes\": 2,\n",
        "      \"checkpoint_path\": \"C:\\\\Users\\\\ACER\\\\Desktop\\\\Project\\\\average_model.pth\",\n",
        "      \"sam_checkpoint_path\": \"C:\\\\coding\\\\python\\\\Project_Nanshang\\\\Project_Nanshang\\\\resources\\\\sam_vit_h_4b8939.pth\",\n",
        "      \"device\": 'cuda' if torch.cuda.is_available() else \"cpu\",\n",
        "      \"confidence_threshold\": 0.35,\n",
        "      \"sam_encoder_version\": \"vit_h\",\n",
        "      \"source_tiffile\": \"C:\\\\coding\\\\python\\\\Project_Nanshang\\\\Project_Nanshang\\\\resources\\\\NanShang_Tomb_cp.tif\",\n",
        "      \"tile_size\": 700,\n",
        "      \"top_left_lat\": 22.97494,\n",
        "      \"top_left_lon\": 120.19544,\n",
        "      \"below_right_lat\": 22.96717,\n",
        "      \"below_right_lon\": 120.19775,\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "-ccV6pP20yWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STOREHOUSE = \"storehouse\"\n",
        "SPLITED_TIFS_DIR = os.path.join(STOREHOUSE, \"splited_tifs\")\n",
        "MASK_DIR = os.path.join(STOREHOUSE, \"masks\")\n",
        "\n",
        "complete_mask_filename = \"map_mask\"\n",
        "COMPLETE_MASK_JPG = os.path.join(STOREHOUSE, complete_mask_filename + \".jpg\")\n",
        "COMPLETE_MASK_TIFF = os.path.join(STOREHOUSE, complete_mask_filename + \".tiff\")\n",
        "COMPLETE_MASK_GEOTIFF = os.path.join(STOREHOUSE, \"geo\" + complete_mask_filename + \".tiff\")\n",
        "\n",
        "OUTPUT_DIR = \"output\"\n",
        "data = {}"
      ],
      "metadata": {
        "id": "q-xUkprm1Dab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### initialize directory"
      ],
      "metadata": {
        "id": "tezphSL22DFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(OUTPUT_DIR)\n",
        "os.mkdir(STOREHOUSE)\n",
        "os.mkdir(SPLITED_TIFS_DIR)\n",
        "os.mkdir(MASK_DIR)"
      ],
      "metadata": {
        "id": "vOWbGw6G1qPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cropping tif"
      ],
      "metadata": {
        "id": "evQTGf5f0SGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from samgeo.common import split_raster\n",
        "\n",
        "split_raster(inputs[\"source_tiffile\"], SPLITED_TIFS_DIR, tile_size=inputs[\"tile_size\"])"
      ],
      "metadata": {
        "id": "S8Tb6D4P0WK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict bounding box"
      ],
      "metadata": {
        "id": "RIZnq-Qg2RCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import models\n",
        "\n",
        "def load_object_detection_model(self, model_arch: str, num_classes: int, checkpoint_path: str, device: str):\n",
        "\n",
        "    trained_model = models.get(\n",
        "    model_arch,\n",
        "    num_classes=num_classes,\n",
        "            checkpoint_path=checkpoint_path\n",
        "        ).to(device)\n",
        "\n",
        "    return trained_model"
      ],
      "metadata": {
        "id": "eD4mmVoF2Y3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tifffile\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "tifs_dir = os.listdir(SPLITED_TIFS_DIR)\n",
        "box_predictor = load_object_detection_model(inputs[\"model_arch\"], inputs[\"num_classes\"],\n",
        "                         inputs[\"checkpoint_path\"], inputs[\"device\"])\n",
        "data[\"detections\"] = {}\n",
        "\n",
        "num_tombs = 0\n",
        "for tif in tifs_dir:\n",
        "    # read tif as numpy array\n",
        "    image = tifffile.imread(os.path.join(SPLITED_TIFS_DIR, tif))\n",
        "    img_array = np.array(image)\n",
        "\n",
        "    # predict bounding box\n",
        "    result = list(box_predictor.predict(img_array, conf=inputs[\"confidence_threshold\"]))[0]\n",
        "    boxes = result.prediction.bboxes_xyxy\n",
        "    num_tombs += len(boxes)  # compute the number of tombs\n",
        "\n",
        "    # make sv.Detections\n",
        "    detection = sv.Detections(\n",
        "             xyxy=boxes,\n",
        "             confidence=result.prediction.confidence,\n",
        "             class_id=result.prediction.labels.astype(int)\n",
        "          )\n",
        "    data[\"detections\"][tif] = detection\n",
        "\n",
        "    # finally we get the total number of tombs\n",
        "    print(f\"the number of tombs is {num_tombs}\")\n",
        "    data[\"num_tombs\"] = num_tombs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D4JMKUtf2W5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict_mask"
      ],
      "metadata": {
        "id": "s7ZfHMk93Idy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "def segment(self, sam_predictor: \"SamPredictor\", image: np.ndarray, xyxy: np.ndarray) -> np.ndarray:\n",
        "    sam_predictor.set_image(image)\n",
        "    result_masks = []\n",
        "    for box in xyxy:\n",
        "        masks, scores, logits = sam_predictor.predict(\n",
        "            box=box,\n",
        "            multimask_output=True\n",
        "        )\n",
        "        index = np.argmax(scores)\n",
        "        result_masks.append(masks[index])\n",
        "    return np.array(result_masks)\n",
        "\n",
        "def load_segment_anything_model(self, sam_encoder_version, sam_checkpoint_path, device):\n",
        "    sam = sam_model_registry[sam_encoder_version](checkpoint=sam_checkpoint_path).to(device=device)\n",
        "    sam_predictor = SamPredictor(sam)\n",
        "    return sam_predictor"
      ],
      "metadata": {
        "id": "hIxUQlWL3H1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "tifs_dir = os.listdir(SPLITED_TIFS_DIR)\n",
        "sam_predictor = load_segment_anything_model(inputs[\"sam_encoder_version\"], inputs[\"sam_checkpoint_path\"],\n",
        "                                    inputs[\"device\"])\n",
        "mask_annotator = sv.MaskAnnotator()\n",
        "\n",
        "for tif in tifs_dir:\n",
        "    # read tif as numpy array\n",
        "    image = tifffile.imread(tif)\n",
        "    img_array = np.array(image)\n",
        "\n",
        "    # make detection's mask\n",
        "    data[\"detection\"][tif].mask = segment(\n",
        "          sam_predictor=sam_predictor,\n",
        "          image=img_array.copy(),\n",
        "          xyxy=data[\"detection\"][tif].xyxy\n",
        "          )\n",
        "\n",
        "    # produce mask and save as image\n",
        "    blank = np.zeros_like(img_array)\n",
        "    mask = mask_annotator.annotate(scene=blank, detections=data[\"detection\"][tif])\n",
        "    img = Image.fromarray(mask, \"RGB\")\n",
        "    img.save(os.path.join(MASK_DIR, \"mask\" + tif[4:8] + \".jpg\"))"
      ],
      "metadata": {
        "id": "0HJ9kQqD3RDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### merge tif"
      ],
      "metadata": {
        "id": "3puZVXvG3jMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal\n",
        "\n",
        "def read_tif(self, tif_path):\n",
        "    ds = gdal.Open(tif_path)\n",
        "    row = ds.RasterXSize\n",
        "    col = ds.RasterYSize\n",
        "    return row, col"
      ],
      "metadata": {
        "id": "3kmCk2Ju3nfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height, width = read_tif(inputs[\"source_tiffile\"])\n",
        "size = inputs[\"tile_size\"]\n",
        "img = Image.new(\"RGB\", (width, height))\n",
        "mask_dir = os.listdir(MASK_DIR)\n",
        "\n",
        "# collage small image to a complete image\n",
        "for mask_filename in mask_dir:\n",
        "    im = Image.open(mask_filename)\n",
        "    i = int(mask_filename[5])      # the 5th str indicate the order in x ray\n",
        "    j = int(mask_filename[7])      # the 7th str indicate the order in y ray (see samgeo.common.split_raster())\n",
        "    img.paste(im, (i * size, j * size))\n",
        "\n",
        "    img.save(COMPLETE_MASK_JPG)\n"
      ],
      "metadata": {
        "id": "9VHiAH1-3mB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### image to geotiff"
      ],
      "metadata": {
        "id": "exgkHC8E37T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import aspose.words as aw\n",
        "import rasterio\n",
        "from rasterio.transform import from_origin\n",
        "\n",
        "def jpg2tiff(self):\n",
        "    doc = aw.Document()\n",
        "    builder = aw.DocumentBuilder(doc)\n",
        "    shape = builder.insert_image(COMPLETE_MASK_JPG)\n",
        "    shape.image_data.save(COMPLETE_MASK_TIFF)\n",
        "\n",
        "def tiff2goetiff(self, below_right_lat, top_left_lat, below_right_lon, top_left_lon):\n",
        "    # Read the input TIFF\n",
        "    with rasterio.open(COMPLETE_MASK_GEOTIFF) as src:\n",
        "        data = src.read()\n",
        "        dtype = src.dtypes[0]\n",
        "        count = src.count\n",
        "        height, width = src.height, src.width\n",
        "\n",
        "    # compute horizontal pixel size and vertical pixel size in degrees\n",
        "    dis_lat = below_right_lat - top_left_lat\n",
        "    dis_lon = below_right_lon - top_left_lon\n",
        "    pixel_size_x = dis_lon / width  # Example: horizontal pixel size in degrees\n",
        "    pixel_size_y = dis_lat / height  # Example: vertical pixel size in degrees\n",
        "\n",
        "    # Define geospatial information\n",
        "    crs = 'EPSG:4326'  # Example: WGS 84\n",
        "\n",
        "    # Define the geotransform\n",
        "    transform = from_origin(top_left_lon, top_left_lat, pixel_size_x, pixel_size_y)\n",
        "\n",
        "    # Write the GeoTIFF file\n",
        "    with rasterio.open(\n",
        "            COMPLETE_MASK_GEOTIFF,\n",
        "            'w',\n",
        "            driver='GTiff',\n",
        "            height=height,\n",
        "            width=width,\n",
        "            count=count,\n",
        "            dtype=dtype,\n",
        "            crs=crs,\n",
        "            transform=transform,\n",
        "    ) as dst:\n",
        "        dst.write(data)"
      ],
      "metadata": {
        "id": "Y6ugO8s33_V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg2tiff()\n",
        "tiff2goetiff(inputs[\"below_right_lat\"], inputs[\"top_left_lat\"],\n",
        "                  inputs[\"below_right_lon\"], inputs[\"top_left_lon\"])"
      ],
      "metadata": {
        "id": "YggtOznC363p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### geotiff to shp"
      ],
      "metadata": {
        "id": "KW3U_rZX4e56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from samgeo.common import raster_to_shp\n",
        "\n",
        "raster_to_shp(COMPLETE_MASK_GEOTIFF, OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "fR4F-zG54iCn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}