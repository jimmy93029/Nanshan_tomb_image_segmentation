{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jimmy93029/shpPredictor/blob/main/shpPredictor/Predicting_mask_for_tifimage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thAvBHRNQcbt"
   },
   "source": [
    "# Predicting_mask_for_tifimage_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sEY9byVQiqq"
   },
   "source": [
    "我們將利用 Training_object_detection_model_workbook 所儲存的 model ，將 tif 檔轉換成特定物件的 shp 遮罩檔。過程中我們會有 5 個步驟，\n",
    "(1) 切分 tif  (2) 預測 bounding box  (3) 利用 SAM 製作 mask.jpg (4) 合併 jpg 檔\n",
    "(5) 將 jpg 檔換成 shp 檔\n",
    "\n",
    "請將 \"sam_checkpoint_path\"、\"average_model.pth\"、\"source_tiffile\" 文件備齊，並將 inputs 各項欄位填妥。**以上各項資料均會影響 shp檔生成結果，請好好填妥**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sOThtfLScxO"
   },
   "source": [
    "### ⚡ Before you start\n",
    "Let's make sure that we have access to GPU. We can use nvidia-smi command to do that. In case of any problems navigate to Edit -> Notebook settings -> Hardware accelerator, set it to GPU, and then click Save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmDnP3PR1FOf"
   },
   "source": [
    "### install package\n",
    "( be aware that super-gradients sometimes change their package ralease version,\n",
    "so please update super-gradients to the latest version to avoid some error about super-gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mH34ZRJ0hgF"
   },
   "outputs": [],
   "source": [
    "%pip install segment-geospatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUqxRdn7ZQr4"
   },
   "outputs": [],
   "source": [
    "!pip install super-gradients==3.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZeQumdZg5oE"
   },
   "outputs": [],
   "source": [
    "!pip install -q supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTHjcvCj3zVY"
   },
   "outputs": [],
   "source": [
    "!pip install aspose-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gREdxdopZgw_"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-z8tV_OdcUQ"
   },
   "source": [
    "如果要下載 segment-anything-model 的模型權重可以解鎖以下的程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlraQVMgdF8e"
   },
   "outputs": [],
   "source": [
    "# %cd {HOME}\n",
    "# !mkdir {HOME}/weights\n",
    "# %cd {HOME}/weights\n",
    "\n",
    "# !wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH-MJJGF1JjQ"
   },
   "source": [
    "### inputs and setting\n",
    "詳細可查看 shpPredictor jupyter book 的 程式碼重要資訊講解，\n",
    "裏頭會細講參數的注意事項"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ccV6pP20yWV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = {\n",
    "      # 模型權重\n",
    "      \"object_detection_model_checkpoint_path\": \"/content/drive/MyDrive/project_NanShang/resources/average_modelbest.pth\",\n",
    "      \"sam_checkpoint_path\": \"/content/drive/MyDrive/project_NanShang/resources/sam_vit_h_4b8939.pth\",\n",
    "\n",
    "      #　dataset class 數目 和 照片來源檔案\n",
    "      \"num_classes\": 2,\n",
    "      \"source_tiffile\": \"/content/drive/MyDrive/project_NanShang/resources/NanShang_Tomb_cp.tif\",\n",
    "\n",
    "      # 物件偵測精準度控制\n",
    "      \"confidence_threshold\": 0.65,\n",
    "      \"tile_size\": 700,\n",
    "\n",
    "      # 照片經緯度資訊\n",
    "      \"top_left_lat\": 22.97494,           # tif 檔左上角的緯度\n",
    "      \"top_left_lon\": 120.19544,          # tif 檔左上角的經度\n",
    "      \"below_right_lat\": 22.96717,         # tif 檔右下角的緯度\n",
    "      \"below_right_lon\": 120.19775,        # tif 檔右下角的經度\n",
    "\n",
    "      \"device\": 'cuda' if torch.cuda.is_available() else \"cpu\",\n",
    "      \"model_arch\": 'yolo_nas_l',\n",
    "      \"sam_encoder_version\": \"vit_h\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-xUkprm1Dab"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "STOREHOUSE = \"storehouse\"\n",
    "SPLITED_TIFS_DIR = os.path.join(STOREHOUSE, \"splited_tifs\")\n",
    "MASK_DIR = os.path.join(STOREHOUSE, \"masks\")\n",
    "\n",
    "complete_mask_filename = \"map_mask\"\n",
    "COMPLETE_MASK_JPG = os.path.join(STOREHOUSE, complete_mask_filename + \".jpg\")\n",
    "COMPLETE_MASK_TIFF = os.path.join(STOREHOUSE, complete_mask_filename + \".tiff\")\n",
    "COMPLETE_MASK_GEOTIFF = os.path.join(STOREHOUSE, \"geo\" + complete_mask_filename + \".tiff\")\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tezphSL22DFk"
   },
   "source": [
    "### initialize directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLNIZgoSFvV1"
   },
   "outputs": [],
   "source": [
    "HOME = os.getcwd()\n",
    "%cd {HOME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOWbGw6G1qPP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(OUTPUT_DIR)\n",
    "os.mkdir(STOREHOUSE)\n",
    "os.mkdir(SPLITED_TIFS_DIR)\n",
    "os.mkdir(MASK_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evQTGf5f0SGF"
   },
   "source": [
    "### Step 1 : Cropping tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8Tb6D4P0WK5"
   },
   "outputs": [],
   "source": [
    "from samgeo.common import split_raster\n",
    "\n",
    "split_raster(inputs[\"source_tiffile\"], SPLITED_TIFS_DIR, tile_size=inputs[\"tile_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIZnq-Qg2RCT"
   },
   "source": [
    "### Step2 : predict bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eD4mmVoF2Y3x"
   },
   "outputs": [],
   "source": [
    "from super_gradients.training import models\n",
    "\n",
    "def load_object_detection_(model_arch: str, num_classes: int, checkpoint_path: str, device: str):\n",
    "\n",
    "    model = models.get(\n",
    "        model_arch,\n",
    "        num_classes=num_classes,\n",
    "        checkpoint_path=checkpoint_path\n",
    "    ).to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4JMKUtf2W5e"
   },
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "tifs_dir = os.listdir(SPLITED_TIFS_DIR)\n",
    "box_predictor = load_object_detection_(inputs[\"model_arch\"], inputs[\"num_classes\"],\n",
    "                         inputs[\"object_detection_model_checkpoint_path\"], inputs[\"device\"])\n",
    "data[\"detections\"] = {}\n",
    "\n",
    "num_tombs = 0\n",
    "for tif in tifs_dir:\n",
    "    # read tif as numpy array\n",
    "    image = tifffile.imread(os.path.join(SPLITED_TIFS_DIR, tif))\n",
    "    img_array = np.array(image)\n",
    "\n",
    "    # predict bounding box\n",
    "    result = list(box_predictor.predict(img_array, conf=inputs[\"confidence_threshold\"]))[0]\n",
    "    boxes = result.prediction.bboxes_xyxy\n",
    "    num_tombs += len(boxes)  # compute the number of tombs\n",
    "\n",
    "    # make sv.Detections\n",
    "    detection = sv.Detections(\n",
    "             xyxy=boxes,\n",
    "             confidence=result.prediction.confidence,\n",
    "             class_id=result.prediction.labels.astype(int)\n",
    "          )\n",
    "    data[\"detections\"][tif] = detection\n",
    "\n",
    "\n",
    "\n",
    "# finally we get the total number of tombs\n",
    "print(f\"the number of tombs is {num_tombs}\")\n",
    "data[\"num_tombs\"] = num_tombs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7ZfHMk93Idy"
   },
   "source": [
    "### Step 3 : predict_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIxUQlWL3H1Q"
   },
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "def segment(sam_predictor: \"SamPredictor\", image: np.ndarray, xyxy: np.ndarray) -> np.ndarray:\n",
    "    sam_predictor.set_image(image)\n",
    "    result_masks = []\n",
    "    for box in xyxy:\n",
    "        masks, scores, logits = sam_predictor.predict(\n",
    "            box=box,\n",
    "            multimask_output=True\n",
    "        )\n",
    "        index = np.argmax(scores)\n",
    "        result_masks.append(masks[index])\n",
    "    return np.array(result_masks)\n",
    "\n",
    "def load_segment_anything_model(sam_encoder_version, sam_checkpoint_path, device):\n",
    "    sam = sam_model_registry[sam_encoder_version](checkpoint=sam_checkpoint_path).to(device=device)\n",
    "    sam_predictor = SamPredictor(sam)\n",
    "    return sam_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HJ9kQqD3RDF"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "tifs_dir = os.listdir(SPLITED_TIFS_DIR)\n",
    "sam_predictor = load_segment_anything_model(inputs[\"sam_encoder_version\"], inputs[\"sam_checkpoint_path\"],\n",
    "                                    inputs[\"device\"])\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "\n",
    "for tif in tifs_dir:\n",
    "    # read tif as numpy array\n",
    "    image = tifffile.imread(os.path.join(SPLITED_TIFS_DIR, tif))\n",
    "    img_array = np.array(image)\n",
    "\n",
    "    # make detection's mask\n",
    "    data[\"detections\"][tif].mask = segment(\n",
    "          sam_predictor=sam_predictor,\n",
    "          image=img_array.copy(),\n",
    "          xyxy=data[\"detections\"][tif].xyxy\n",
    "          )\n",
    "\n",
    "    # produce mask and save as image\n",
    "    blank = np.zeros_like(img_array)\n",
    "    mask = mask_annotator.annotate(scene=blank, detections=data[\"detections\"][tif])\n",
    "    img = Image.fromarray(mask, \"RGB\")\n",
    "    img.save(os.path.join(MASK_DIR, \"mask\" + tif[4:-4] + \".jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3puZVXvG3jMV"
   },
   "source": [
    "### Step 4 : merge image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kmCk2Ju3nfG"
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "def read_tif(tif_path):\n",
    "    ds = gdal.Open(tif_path)\n",
    "    row = ds.RasterXSize\n",
    "    col = ds.RasterYSize\n",
    "    return row, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VHiAH1-3mB6"
   },
   "outputs": [],
   "source": [
    "width, height = read_tif(inputs[\"source_tiffile\"])\n",
    "size = inputs[\"tile_size\"]\n",
    "img = Image.new(\"RGB\", (width, height))\n",
    "mask_dir = os.listdir(MASK_DIR)\n",
    "\n",
    "# collage small image to a complete image\n",
    "for mask_filename in mask_dir:\n",
    "    im = Image.open(os.path.join(MASK_DIR, mask_filename))\n",
    "    name_list = mask_filename[:-4].split(\"_\")  # ex. turn mask_0_11.jpg into ['mask', '0', '11']\n",
    "    i = int(name_list[1])      # the 1th value in name_list indicate the order in x ray\n",
    "    j = int(name_list[2])      # the 2th value in name_list indicate the order in y ray (see samgeo.common.split_raster())\n",
    "    img.paste(im, (i * size, j * size))\n",
    "\n",
    "img.save(COMPLETE_MASK_JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exgkHC8E37T8"
   },
   "source": [
    "### Step 5 - 1: image to geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6ugO8s33_V2"
   },
   "outputs": [],
   "source": [
    "import aspose.words as aw\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "def jpg2tiff():\n",
    "    doc = aw.Document()\n",
    "    builder = aw.DocumentBuilder(doc)\n",
    "    shape = builder.insert_image(COMPLETE_MASK_JPG)\n",
    "    shape.image_data.save(COMPLETE_MASK_TIFF)\n",
    "\n",
    "def tiff2goetiff(below_right_lat, top_left_lat, below_right_lon, top_left_lon):\n",
    "    # Read the input TIFF\n",
    "    with rasterio.open(COMPLETE_MASK_GEOTIFF) as src:\n",
    "        data = src.read()\n",
    "        dtype = src.dtypes[0]\n",
    "        count = src.count\n",
    "        height, width = src.height, src.width\n",
    "\n",
    "    # compute horizontal pixel size and vertical pixel size in degrees\n",
    "    dis_lat = below_right_lat - top_left_lat\n",
    "    dis_lon = below_right_lon - top_left_lon\n",
    "    pixel_size_x = dis_lon / width  # Example: horizontal pixel size in degrees\n",
    "    pixel_size_y = dis_lat / height  # Example: vertical pixel size in degrees\n",
    "\n",
    "    # Define geospatial information\n",
    "    crs = 'EPSG:4326'  # Example: WGS 84\n",
    "\n",
    "    # Define the geotransform\n",
    "    transform = from_origin(top_left_lon, top_left_lat, pixel_size_x, pixel_size_y)\n",
    "\n",
    "    # Write the GeoTIFF file\n",
    "    with rasterio.open(\n",
    "            COMPLETE_MASK_GEOTIFF,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=count,\n",
    "            dtype=dtype,\n",
    "            crs=crs,\n",
    "            transform=transform,\n",
    "    ) as dst:\n",
    "        dst.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YggtOznC363p"
   },
   "outputs": [],
   "source": [
    "jpg2tiff()\n",
    "tiff2goetiff(inputs[\"below_right_lat\"], inputs[\"top_left_lat\"],\n",
    "                  inputs[\"below_right_lon\"], inputs[\"top_left_lon\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KW3U_rZX4e56"
   },
   "source": [
    "### Step 5 - 2: geotiff to shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fR4F-zG54iCn"
   },
   "outputs": [],
   "source": [
    "from samgeo.common import raster_to_shp\n",
    "\n",
    "raster_to_shp(COMPLETE_MASK_GEOTIFF, OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPsUubgOOqUXlIL4mdWJ6kF",
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "mount_file_id": "https://github.com/jimmy93029/shpPredictor/blob/main/shpPredictor/Predicting_mask_for_tifimage.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}