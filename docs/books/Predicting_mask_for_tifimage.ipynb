{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "https://github.com/jimmy93029/shpPredictor/blob/main/docs/books/Predicting_mask_for_tifimage.ipynb",
      "authorship_tag": "ABX9TyO/0nZ6F8A/zF4b3wCOIIiU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmy93029/shpPredictor/blob/main/docs/books/Predicting_mask_for_tifimage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting_mask_for_tifimage"
      ],
      "metadata": {
        "id": "thAvBHRNQcbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我們將利用 Training_object_detection_model_workbook 所儲存的 model ，將 tif 檔轉換成特定物件的 shp 遮罩檔。過程中我們會有 5 個步驟，\n",
        "(1) 切分 tif  (2) 預測 bounding box  (3) 利用 SAM 製作 mask.jpg (4) 合併 jpg 檔\n",
        "(5) 將 jpg 檔換成 shp 檔\n",
        "\n",
        "請將 \"sam_checkpoint_path\"、\"average_model.pth\"、\"source_tiffile\" 文件備齊，並將 inputs 各項欄位填妥。**以上各項資料均會影響 shp檔生成結果，請好好填妥**"
      ],
      "metadata": {
        "id": "6sEY9byVQiqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚡ Before you start\n",
        "Let's make sure that we have access to GPU. We can use nvidia-smi command to do that. In case of any problems navigate to Edit -> Notebook settings -> Hardware accelerator, set it to GPU, and then click Save."
      ],
      "metadata": {
        "id": "0sOThtfLScxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install package\n",
        "( be aware that super-gradients sometimes change their package ralease version,\n",
        "so please update super-gradients to the latest version to avoid some error about super-gradients)"
      ],
      "metadata": {
        "id": "OmDnP3PR1FOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install segment-geospatial"
      ],
      "metadata": {
        "id": "2mH34ZRJ0hgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install super-gradients==3.2.0"
      ],
      "metadata": {
        "id": "eUqxRdn7ZQr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q supervision"
      ],
      "metadata": {
        "id": "EZeQumdZg5oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aspose-words"
      ],
      "metadata": {
        "id": "gTHjcvCj3zVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "%cd {HOME}\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git"
      ],
      "metadata": {
        "id": "gREdxdopZgw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "如果要下載 segment-anything-model 的模型權重可以解鎖以下的程式碼"
      ],
      "metadata": {
        "id": "s-z8tV_OdcUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!mkdir {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ],
      "metadata": {
        "id": "rlraQVMgdF8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### inputs and setting\n",
        "詳細可查看 shpPredictor jupyter book 的 程式碼重要資訊講解，\n",
        "裏頭會細講參數的注意事項"
      ],
      "metadata": {
        "id": "hH-MJJGF1JjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* inputs"
      ],
      "metadata": {
        "id": "8iGmYtrEYm3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "inputs = {\n",
        "      # 模型權重\n",
        "      \"object_detection_model_checkpoint_path\": \"/content/drive/MyDrive/project_NanShang/resources/average_modelv10_80epochs.pth\",\n",
        "      \"sam_checkpoint_path\": \"/content/weights/sam_vit_h_4b8939.pth\",\n",
        "\n",
        "      #　dataset class 數目 和 照片來源檔案\n",
        "      \"num_classes\": 2,\n",
        "      \"source_tiffile\": \"/content/drive/MyDrive/project_NanShang/resources/Nanshan2.tif\",\n",
        "\n",
        "      # 物件偵測精準度控制\n",
        "      \"confidence_threshold\": 0.65,\n",
        "      \"tile_size\": 700,\n",
        "\n",
        "      # 照片經緯度資訊\n",
        "      \"top_left_lat\": 22.9749,           # tif 檔左上角的緯度\n",
        "      \"top_left_lon\": 120.1977,          # tif 檔左上角的經度\n",
        "      \"below_right_lat\": 22.9673,         # tif 檔右下角的緯度\n",
        "      \"below_right_lon\": 120.2033,        # tif 檔右下角的經度\n",
        "\n",
        "      \"device\": 'cuda' if torch.cuda.is_available() else \"cpu\",\n",
        "      \"model_arch\": 'yolo_nas_l',\n",
        "      \"sam_encoder_version\": \"vit_h\",\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "-ccV6pP20yWV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* settings"
      ],
      "metadata": {
        "id": "y4wXgPhPYjew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "STOREHOUSE = \"storehouse\"\n",
        "SPLITED_TIFS_DIR = os.path.join(STOREHOUSE, \"splited_tifs\")\n",
        "MASK_DIR = os.path.join(STOREHOUSE, \"masks\")\n",
        "\n",
        "complete_mask_filename = \"map_mask\"\n",
        "COMPLETE_MASK_JPG = os.path.join(STOREHOUSE, complete_mask_filename + \".jpg\")\n",
        "COMPLETE_MASK_TIFF = os.path.join(STOREHOUSE, complete_mask_filename + \".tiff\")\n",
        "COMPLETE_MASK_GEOTIFF = os.path.join(STOREHOUSE, \"geo\" + complete_mask_filename + \".tiff\")\n",
        "\n",
        "OUTPUT_DIR = \"output\"\n",
        "data = {}"
      ],
      "metadata": {
        "id": "q-xUkprm1Dab"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### initialize directory"
      ],
      "metadata": {
        "id": "tezphSL22DFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "%cd {HOME}\n",
        "\n",
        "os.makedirs(OUTPUT_DIR)\n",
        "os.mkdir(STOREHOUSE)\n",
        "os.mkdir(SPLITED_TIFS_DIR)\n",
        "os.mkdir(MASK_DIR)"
      ],
      "metadata": {
        "id": "vOWbGw6G1qPP",
        "outputId": "a8099709-ef9a-4a76-c235-c7881411af3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 : Cropping tif"
      ],
      "metadata": {
        "id": "evQTGf5f0SGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from samgeo.common import split_raster\n",
        "\n",
        "split_raster(inputs[\"source_tiffile\"], SPLITED_TIFS_DIR, tile_size=inputs[\"tile_size\"])"
      ],
      "metadata": {
        "id": "S8Tb6D4P0WK5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step2 : predict bounding box"
      ],
      "metadata": {
        "id": "RIZnq-Qg2RCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import models\n",
        "\n",
        "def load_object_detection_(model_arch: str, num_classes: int, checkpoint_path: str, device: str):\n",
        "\n",
        "    model = models.get(\n",
        "        model_arch,\n",
        "        num_classes=num_classes,\n",
        "        checkpoint_path=checkpoint_path\n",
        "    ).to(device)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "eD4mmVoF2Y3x"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tifffile\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "tifs_dir = os.listdir(SPLITED_TIFS_DIR)\n",
        "box_predictor = load_object_detection_(inputs[\"model_arch\"], inputs[\"num_classes\"],\n",
        "                         inputs[\"object_detection_model_checkpoint_path\"], inputs[\"device\"])\n",
        "data[\"detections\"] = {}\n",
        "\n",
        "num_tombs = 0\n",
        "for tif in tifs_dir:\n",
        "    # read tif as numpy array\n",
        "    image = tifffile.imread(os.path.join(SPLITED_TIFS_DIR, tif))\n",
        "    img_array = np.array(image)\n",
        "\n",
        "    # predict bounding box\n",
        "    result = list(box_predictor.predict(img_array, conf=inputs[\"confidence_threshold\"]))[0]\n",
        "    boxes = result.prediction.bboxes_xyxy\n",
        "    num_tombs += len(boxes)  # compute the number of tombs\n",
        "\n",
        "    # make sv.Detections\n",
        "    detection = sv.Detections(\n",
        "             xyxy=boxes,\n",
        "             confidence=result.prediction.confidence,\n",
        "             class_id=result.prediction.labels.astype(int)\n",
        "          )\n",
        "    data[\"detections\"][tif] = detection\n",
        "\n",
        "\n",
        "\n",
        "# finally we get the total number of tombs\n",
        "print(f\"the number of tombs is {num_tombs}\")\n",
        "data[\"num_tombs\"] = num_tombs\n"
      ],
      "metadata": {
        "id": "D4JMKUtf2W5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 : predict_mask"
      ],
      "metadata": {
        "id": "s7ZfHMk93Idy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "def segment(sam_predictor: \"SamPredictor\", image: np.ndarray, xyxy: np.ndarray) -> np.ndarray:\n",
        "    sam_predictor.set_image(image)\n",
        "    result_masks = []\n",
        "    for box in xyxy:\n",
        "        masks, scores, logits = sam_predictor.predict(\n",
        "            box=box,\n",
        "            multimask_output=True\n",
        "        )\n",
        "        index = np.argmax(scores)\n",
        "        result_masks.append(masks[index])\n",
        "    return np.array(result_masks)\n",
        "\n",
        "def load_segment_anything_model(sam_encoder_version, sam_checkpoint_path, device):\n",
        "    sam = sam_model_registry[sam_encoder_version](checkpoint=sam_checkpoint_path).to(device=device)\n",
        "    sam_predictor = SamPredictor(sam)\n",
        "    return sam_predictor"
      ],
      "metadata": {
        "id": "hIxUQlWL3H1Q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "tifs_dir = os.listdir(SPLITED_TIFS_DIR)\n",
        "sam_predictor = load_segment_anything_model(inputs[\"sam_encoder_version\"], inputs[\"sam_checkpoint_path\"],\n",
        "                                    inputs[\"device\"])\n",
        "mask_annotator = sv.MaskAnnotator()\n",
        "\n",
        "for tif in tifs_dir:\n",
        "    # read tif as numpy array\n",
        "    image = tifffile.imread(os.path.join(SPLITED_TIFS_DIR, tif))\n",
        "    img_array = np.array(image)\n",
        "\n",
        "    # make detection's mask\n",
        "    data[\"detections\"][tif].mask = segment(\n",
        "          sam_predictor=sam_predictor,\n",
        "          image=img_array.copy(),\n",
        "          xyxy=data[\"detections\"][tif].xyxy\n",
        "          )\n",
        "\n",
        "    # produce mask and save as image\n",
        "    blank = np.zeros_like(img_array)\n",
        "    mask = mask_annotator.annotate(scene=blank, detections=data[\"detections\"][tif])\n",
        "    img = Image.fromarray(mask, \"RGB\")\n",
        "    img.save(os.path.join(MASK_DIR, \"mask\" + tif[4:-4] + \".jpg\"))"
      ],
      "metadata": {
        "id": "0HJ9kQqD3RDF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 : merge image"
      ],
      "metadata": {
        "id": "3puZVXvG3jMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal\n",
        "\n",
        "def read_tif(tif_path):\n",
        "    ds = gdal.Open(tif_path)\n",
        "    row = ds.RasterXSize\n",
        "    col = ds.RasterYSize\n",
        "    return row, col"
      ],
      "metadata": {
        "id": "3kmCk2Ju3nfG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width, height = read_tif(inputs[\"source_tiffile\"])\n",
        "size = inputs[\"tile_size\"]\n",
        "img = Image.new(\"RGB\", (width, height))\n",
        "mask_dir = os.listdir(MASK_DIR)\n",
        "\n",
        "# collage small image to a complete image\n",
        "for mask_filename in mask_dir:\n",
        "    im = Image.open(os.path.join(MASK_DIR, mask_filename))\n",
        "    name_list = mask_filename[:-4].split(\"_\")  # ex. turn mask_0_11.jpg into ['mask', '0', '11']\n",
        "    i = int(name_list[1])      # the 1th value in name_list indicate the order in x ray\n",
        "    j = int(name_list[2])      # the 2th value in name_list indicate the order in y ray (see samgeo.common.split_raster())\n",
        "    img.paste(im, (i * size, j * size))\n",
        "\n",
        "img.save(COMPLETE_MASK_JPG)\n"
      ],
      "metadata": {
        "id": "9VHiAH1-3mB6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 - 1: image to geotiff\n",
        "執行這一步時很吃 RAM。如果 Colab 工作階段因異常原因而中止，那滿有可能是 RAM 不足的問題"
      ],
      "metadata": {
        "id": "exgkHC8E37T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import aspose.words as aw\n",
        "import rasterio\n",
        "from rasterio.transform import from_origin\n",
        "\n",
        "def jpg2tiff():\n",
        "    doc = aw.Document()\n",
        "    builder = aw.DocumentBuilder(doc)\n",
        "    shape = builder.insert_image(COMPLETE_MASK_JPG)\n",
        "    shape.image_data.save(COMPLETE_MASK_TIFF)\n",
        "\n",
        "def tiff2goetiff(below_right_lat, top_left_lat, below_right_lon, top_left_lon):\n",
        "    # Read the input TIFF\n",
        "    with rasterio.open(COMPLETE_MASK_GEOTIFF) as src:\n",
        "        data = src.read()\n",
        "        dtype = src.dtypes[0]\n",
        "        count = src.count\n",
        "        height, width = src.height, src.width\n",
        "\n",
        "    # compute horizontal pixel size and vertical pixel size in degrees\n",
        "    dis_lat = below_right_lat - top_left_lat\n",
        "    dis_lon = below_right_lon - top_left_lon\n",
        "    pixel_size_x = dis_lon / width  # Example: horizontal pixel size in degrees\n",
        "    pixel_size_y = dis_lat / height  # Example: vertical pixel size in degrees\n",
        "\n",
        "    # Define geospatial information\n",
        "    crs = 'EPSG:4326'  # Example: WGS 84\n",
        "\n",
        "    # Define the geotransform\n",
        "    transform = from_origin(top_left_lon, top_left_lat, pixel_size_x, pixel_size_y)\n",
        "\n",
        "    # Write the GeoTIFF file\n",
        "    with rasterio.open(\n",
        "            COMPLETE_MASK_GEOTIFF,\n",
        "            'w',\n",
        "            driver='GTiff',\n",
        "            height=height,\n",
        "            width=width,\n",
        "            count=count,\n",
        "            dtype=dtype,\n",
        "            crs=crs,\n",
        "            transform=transform,\n",
        "    ) as dst:\n",
        "        dst.write(data)"
      ],
      "metadata": {
        "id": "Y6ugO8s33_V2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg2tiff()\n",
        "tiff2goetiff(inputs[\"below_right_lat\"], inputs[\"top_left_lat\"],\n",
        "                  inputs[\"below_right_lon\"], inputs[\"top_left_lon\"])"
      ],
      "metadata": {
        "id": "YggtOznC363p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 - 2: geotiff to shp"
      ],
      "metadata": {
        "id": "KW3U_rZX4e56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from samgeo.common import raster_to_shp\n",
        "\n",
        "raster_to_shp(COMPLETE_MASK_GEOTIFF, OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "fR4F-zG54iCn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}